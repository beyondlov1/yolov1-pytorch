{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from tqdm import tqdm_gui\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(100)\n",
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self) -> None:\n",
    "        self.datasetdir = \"/media/beyond/70f23ead-fa6d-4628-acf7-c82133c03245/home/beyond/Documents/ml/data/dataset/image/VOCdevkit/VOC2012\"\n",
    "        \n",
    "        self.size = 512\n",
    "        self.batch_size = 1\n",
    "\n",
    "        self.lr = 1e-3\n",
    "        self.epochs = 100\n",
    "\n",
    "        self.max_interset_iou = 0.1\n",
    "        self.min_confidence = 0.4\n",
    "\n",
    "        self.classlist = [\n",
    "            'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "            'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "            'cow', 'diningtable', 'dog', 'horse',\n",
    "            'motorbike', 'person', 'pottedplant',\n",
    "            'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "        \n",
    "        self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': '2010_006026',\n",
       " 'width': 332,\n",
       " 'height': 500,\n",
       " 'boxes': [{'classname': 'sheep', 'bbox': [87, 412, 147, 463]},\n",
       "  {'classname': 'sheep', 'bbox': [100, 353, 144, 382]},\n",
       "  {'classname': 'sheep', 'bbox': [141, 373, 183, 389]}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "\n",
    "def parse_rec(filename:str):\n",
    "    \"\"\" Parse a PASCAL VOC xml file \"\"\"\n",
    "    tree = ET.parse(filename)\n",
    "    result = {}\n",
    "    result[\"filename\"] = filename[filename.rindex(\"/\")+1:-4]\n",
    "    result[\"width\"] = int(tree.find(\"size\").find(\"width\").text)\n",
    "    result[\"height\"] = int(tree.find(\"size\").find(\"height\").text)\n",
    "    result[\"boxes\"] = []\n",
    "    for object in tree.findall('object'):\n",
    "        obj = {}\n",
    "        # difficult = int(object.find('difficult').text)\n",
    "        # if difficult == 1:\n",
    "        #     continue\n",
    "        obj['classname'] = object.find('name').text\n",
    "        bbox = object.find('bndbox')\n",
    "        obj['bbox'] = [int(float(bbox.find('xmin').text)),\n",
    "                              int(float(bbox.find('ymin').text)),\n",
    "                              int(float(bbox.find('xmax').text)),\n",
    "                              int(float(bbox.find('ymax').text))]\n",
    "        result[\"boxes\"].append(obj)\n",
    "    return result\n",
    "\n",
    "\n",
    "axmlpath = os.path.join(config.datasetdir, \"Annotations\",\"2010_006026.xml\")\n",
    "parse_rec(axmlpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 5001/17125 [00:50<02:03, 98.26it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    image_size = 448\n",
    "\n",
    "    def __init__(self, config:Config, transform = [], istrain=True):\n",
    "        print('loading annotations')\n",
    "        self.config = config\n",
    "        self.istrain = istrain\n",
    "        self.transform = transform\n",
    "        self.fnames = []\n",
    "        self.boxes = []\n",
    "        self.labels = []\n",
    "        self.S = 7  # grid number 7*7 normally\n",
    "        self.B = 2  # bounding box number in each grid\n",
    "        self.C = 20  # how many classes\n",
    "        self.mean = (123, 117, 104)  # RGB\n",
    "        annodir = os.path.join(config.datasetdir, \"Annotations\")\n",
    "        i = 0\n",
    "        for filename in tqdm(os.listdir(annodir)):\n",
    "            if i > 1:\n",
    "                break\n",
    "            rect = parse_rec(os.path.join(annodir, filename))\n",
    "            self.fnames.append(rect[\"filename\"] + \".jpg\") \n",
    "            boxes = []\n",
    "            label = []\n",
    "            for box in rect[\"boxes\"]:\n",
    "                x1 = box[\"bbox\"][0]\n",
    "                y1 = box[\"bbox\"][1]\n",
    "                x2 = box[\"bbox\"][2]\n",
    "                y2 = box[\"bbox\"][3]\n",
    "                boxes.append([x1, y1, x2, y2])\n",
    "                label.append(config.classlist.index(box[\"classname\"]))\n",
    "            self.boxes.append(torch.Tensor(boxes))\n",
    "            self.labels.append(torch.LongTensor(label))\n",
    "            i = i + 1\n",
    "        # self.num_samples = len(self.boxes)\n",
    "        self.num_samples = min(len(self.fnames),i)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.fnames[idx]\n",
    "        img = cv2.imread(os.path.join(config.datasetdir, \"JPEGImages\", fname))\n",
    "        boxes = self.boxes[idx].clone()\n",
    "        labels = self.labels[idx].clone()\n",
    "        if self.istrain:  # 数据增强里面的各种变换用torch自带的transform是做不到的，因为对图片进行旋转、随即裁剪等会造成bbox的坐标也会发生变化，所以需要自己来定义数据增强\n",
    "            img, boxes = self.random_flip(img, boxes)\n",
    "            img, boxes = self.randomScale(img, boxes)\n",
    "            img = self.randomBlur(img)\n",
    "            img = self.RandomBrightness(img)\n",
    "            img = self.RandomHue(img)\n",
    "            img = self.RandomSaturation(img)\n",
    "            img, boxes, labels = self.randomShift(img, boxes, labels)\n",
    "            img, boxes, labels = self.randomCrop(img, boxes, labels)\n",
    "        h, w, _ = img.shape\n",
    "        boxes /= torch.Tensor([w, h, w, h]).expand_as(boxes)         # 坐标 归一化 处理，为了方便训练\n",
    "        img = self.BGR2RGB(img)                                                                           # because pytorch pretrained model use RGB\n",
    "        # img = self.subMean(img, self.mean)                          # 减去均值\n",
    "        img = cv2.resize(img, (self.image_size, self.image_size))   # 将所有图片都resize到指定大小\n",
    "        img = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])(img)\n",
    "        target = self.encoder(boxes, labels)                        # 将图片标签编码到7x7*30的向量\n",
    "\n",
    "        for t in self.transform:\n",
    "            img = t(img)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def encoder(self, boxes, labels):\n",
    "        '''\n",
    "        boxes (tensor) [[x1,y1,x2,y2],[]]  归一化后的结果\n",
    "        labels (tensor) [...]\n",
    "        return 7x7x30\n",
    "        '''\n",
    "        grid_num = 7\n",
    "        target = torch.zeros((grid_num, grid_num, 30))\n",
    "        cell_size = 1. / grid_num                         # 每个格子的大小\n",
    "\n",
    "        # 右下坐标        左上坐标\n",
    "        # x2,y2           x1,y1\n",
    "        wh = boxes[:, 2:] - boxes[:, :2]\n",
    "\n",
    "        # 物体中心坐标集合\n",
    "        cxcy = (boxes[:, 2:] + boxes[:, :2]) / 2\n",
    "        for i in range(cxcy.size()[0]):\n",
    "            # 物体中心坐标\n",
    "            cxcy_sample = cxcy[i]\n",
    "\n",
    "            # 指示落在那网格，如[0,0]\n",
    "            ij = cxcy_sample // cell_size  # 中心点对应格子的坐标\n",
    "            #    0 1    2 3   4      5 6   7 8   9\n",
    "            # [中心坐标,长宽,置信度,中心坐标,长宽,置信度, 20个类别] x 7x7   因为一个框预测两个物体\n",
    "\n",
    "            xy = ij * cell_size\n",
    "            delta_xy = (cxcy_sample - xy) / cell_size\n",
    "            target[int(ij[1]), int(ij[0]), :2] = delta_xy\n",
    "            target[int(ij[1]), int(ij[0]), 2:4] = wh[i]\n",
    "            target[int(ij[1]), int(ij[0]), 5:7] = delta_xy\n",
    "            target[int(ij[1]), int(ij[0]), 7:9] = wh[i]\n",
    "\n",
    "            # 第一/二个框的置信度\n",
    "            target[int(ij[1]), int(ij[0]), 4] = 1\n",
    "            target[int(ij[1]), int(ij[0]), 9] = 1\n",
    "\n",
    "            target[int(ij[1]), int(ij[0]), int(labels[i]) + 10] = 1\n",
    "        return target\n",
    "\n",
    "    def BGR2RGB(self, img):\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    def BGR2HSV(self, img):\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    def HSV2BGR(self, img):\n",
    "        return cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    def RandomBrightness(self, bgr):\n",
    "        if random.random() < 0.5:\n",
    "            hsv = self.BGR2HSV(bgr)\n",
    "            h, s, v = cv2.split(hsv)\n",
    "            adjust = random.choice([0.5, 1.5])\n",
    "            v = v * adjust\n",
    "            v = np.clip(v, 0, 255).astype(hsv.dtype)\n",
    "            hsv = cv2.merge((h, s, v))\n",
    "            bgr = self.HSV2BGR(hsv)\n",
    "        return bgr\n",
    "\n",
    "    def RandomSaturation(self, bgr):\n",
    "        if random.random() < 0.5:\n",
    "            hsv = self.BGR2HSV(bgr)\n",
    "            h, s, v = cv2.split(hsv)\n",
    "            adjust = random.choice([0.5, 1.5])\n",
    "            s = s * adjust\n",
    "            s = np.clip(s, 0, 255).astype(hsv.dtype)\n",
    "            hsv = cv2.merge((h, s, v))\n",
    "            bgr = self.HSV2BGR(hsv)\n",
    "        return bgr\n",
    "\n",
    "    def RandomHue(self, bgr):\n",
    "        if random.random() < 0.5:\n",
    "            hsv = self.BGR2HSV(bgr)\n",
    "            h, s, v = cv2.split(hsv)\n",
    "            adjust = random.choice([0.5, 1.5])\n",
    "            h = h * adjust\n",
    "            h = np.clip(h, 0, 255).astype(hsv.dtype)\n",
    "            hsv = cv2.merge((h, s, v))\n",
    "            bgr = self.HSV2BGR(hsv)\n",
    "        return bgr\n",
    "\n",
    "    def randomBlur(self, bgr):\n",
    "        if random.random() < 0.5:\n",
    "            bgr = cv2.blur(bgr, (5, 5))\n",
    "        return bgr\n",
    "\n",
    "    def randomShift(self, bgr, boxes, labels):\n",
    "        # 平移变换\n",
    "        center = (boxes[:, 2:] + boxes[:, :2]) / 2\n",
    "        if random.random() < 0.5:\n",
    "            height, width, c = bgr.shape\n",
    "            after_shfit_image = np.zeros((height, width, c), dtype=bgr.dtype)\n",
    "            after_shfit_image[:, :, :] = (104, 117, 123)  # bgr\n",
    "            shift_x = random.uniform(-width * 0.2, width * 0.2)\n",
    "            shift_y = random.uniform(-height * 0.2, height * 0.2)\n",
    "            # print(bgr.shape,shift_x,shift_y)\n",
    "            # 原图像的平移\n",
    "            if shift_x >= 0 and shift_y >= 0:\n",
    "                after_shfit_image[int(shift_y):,\n",
    "                                  int(shift_x):,\n",
    "                                  :] = bgr[:height - int(shift_y),\n",
    "                                           :width - int(shift_x),\n",
    "                                           :]\n",
    "            elif shift_x >= 0 and shift_y < 0:\n",
    "                after_shfit_image[:height + int(shift_y),\n",
    "                                  int(shift_x):,\n",
    "                                  :] = bgr[-int(shift_y):,\n",
    "                                           :width - int(shift_x),\n",
    "                                           :]\n",
    "            elif shift_x < 0 and shift_y >= 0:\n",
    "                after_shfit_image[int(shift_y):, :width +\n",
    "                                  int(shift_x), :] = bgr[:height -\n",
    "                                                         int(shift_y), -\n",
    "                                                         int(shift_x):, :]\n",
    "            elif shift_x < 0 and shift_y < 0:\n",
    "                after_shfit_image[:height + int(shift_y), :width + int(\n",
    "                    shift_x), :] = bgr[-int(shift_y):, -int(shift_x):, :]\n",
    "\n",
    "            shift_xy = torch.FloatTensor(\n",
    "                [[int(shift_x), int(shift_y)]]).expand_as(center)\n",
    "            center = center + shift_xy\n",
    "            mask1 = (center[:, 0] > 0) & (center[:, 0] < width)\n",
    "            mask2 = (center[:, 1] > 0) & (center[:, 1] < height)\n",
    "            mask = (mask1 & mask2).view(-1, 1)\n",
    "            boxes_in = boxes[mask.expand_as(boxes)].view(-1, 4)\n",
    "            if len(boxes_in) == 0:\n",
    "                return bgr, boxes, labels\n",
    "            box_shift = torch.FloatTensor(\n",
    "                [[int(shift_x), int(shift_y), int(shift_x), int(shift_y)]]).expand_as(boxes_in)\n",
    "            boxes_in = boxes_in + box_shift\n",
    "            labels_in = labels[mask.view(-1)]\n",
    "            return after_shfit_image, boxes_in, labels_in\n",
    "        return bgr, boxes, labels\n",
    "\n",
    "    def randomScale(self, bgr, boxes):\n",
    "        # 固定住高度，以0.8-1.2伸缩宽度，做图像形变\n",
    "        if random.random() < 0.5:\n",
    "            scale = random.uniform(0.8, 1.2)\n",
    "            height, width, c = bgr.shape\n",
    "            bgr = cv2.resize(bgr, (int(width * scale), height))\n",
    "            scale_tensor = torch.FloatTensor(\n",
    "                [[scale, 1, scale, 1]]).expand_as(boxes)\n",
    "            boxes = boxes * scale_tensor\n",
    "            return bgr, boxes\n",
    "        return bgr, boxes\n",
    "\n",
    "    def randomCrop(self, bgr, boxes, labels):\n",
    "        if random.random() < 0.5:\n",
    "            center = (boxes[:, 2:] + boxes[:, :2]) / 2\n",
    "            height, width, c = bgr.shape\n",
    "            h = random.uniform(0.6 * height, height)\n",
    "            w = random.uniform(0.6 * width, width)\n",
    "            x = random.uniform(0, width - w)\n",
    "            y = random.uniform(0, height - h)\n",
    "            x, y, h, w = int(x), int(y), int(h), int(w)\n",
    "\n",
    "            center = center - torch.FloatTensor([[x, y]]).expand_as(center)\n",
    "            mask1 = (center[:, 0] > 0) & (center[:, 0] < w)\n",
    "            mask2 = (center[:, 1] > 0) & (center[:, 1] < h)\n",
    "            mask = (mask1 & mask2).view(-1, 1)\n",
    "\n",
    "            boxes_in = boxes[mask.expand_as(boxes)].view(-1, 4)\n",
    "            if(len(boxes_in) == 0):\n",
    "                return bgr, boxes, labels\n",
    "            box_shift = torch.FloatTensor([[x, y, x, y]]).expand_as(boxes_in)\n",
    "\n",
    "            boxes_in = boxes_in - box_shift\n",
    "            boxes_in[:, 0] = boxes_in[:, 0].clamp_(min=0, max=w)\n",
    "            boxes_in[:, 2] = boxes_in[:, 2].clamp_(min=0, max=w)\n",
    "            boxes_in[:, 1] = boxes_in[:, 1].clamp_(min=0, max=h)\n",
    "            boxes_in[:, 3] = boxes_in[:, 3].clamp_(min=0, max=h)\n",
    "\n",
    "            labels_in = labels[mask.view(-1)]\n",
    "            img_croped = bgr[y:y + h, x:x + w, :]\n",
    "            return img_croped, boxes_in, labels_in\n",
    "        return bgr, boxes, labels\n",
    "\n",
    "    def subMean(self, bgr, mean):\n",
    "        mean = np.array(mean, dtype=np.float32)\n",
    "        bgr = bgr - mean\n",
    "        return bgr\n",
    "\n",
    "    def random_flip(self, im, boxes):\n",
    "        if random.random() < 0.5:\n",
    "            im_lr = np.fliplr(im).copy()\n",
    "            h, w, _ = im.shape\n",
    "            xmin = w - boxes[:, 2]\n",
    "            xmax = w - boxes[:, 0]\n",
    "            boxes[:, 0] = xmin\n",
    "            boxes[:, 2] = xmax\n",
    "            return im_lr, boxes\n",
    "        return im, boxes\n",
    "\n",
    "    def random_bright(self, im, delta=16):\n",
    "        alpha = random.random()\n",
    "        if alpha > 0.3:\n",
    "            im = im * alpha + random.randrange(-delta, delta)\n",
    "            im = im.clip(min=0, max=255).astype(np.uint8)\n",
    "        return im\n",
    "\n",
    "\n",
    "dataset = MyDataset(config, istrain=False)\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [1, 7, 7, 30]             --\n",
       "├─Conv2d: 1-1                            [1, 64, 224, 224]         9,408\n",
       "├─BatchNorm2d: 1-2                       [1, 64, 224, 224]         128\n",
       "├─ReLU: 1-3                              [1, 64, 224, 224]         --\n",
       "├─MaxPool2d: 1-4                         [1, 64, 112, 112]         --\n",
       "├─Sequential: 1-5                        [1, 256, 112, 112]        --\n",
       "│    └─Bottleneck: 2-1                   [1, 256, 112, 112]        --\n",
       "│    │    └─Conv2d: 3-1                  [1, 64, 112, 112]         4,096\n",
       "│    │    └─BatchNorm2d: 3-2             [1, 64, 112, 112]         128\n",
       "│    │    └─ReLU: 3-3                    [1, 64, 112, 112]         --\n",
       "│    │    └─Conv2d: 3-4                  [1, 64, 112, 112]         36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [1, 64, 112, 112]         128\n",
       "│    │    └─ReLU: 3-6                    [1, 64, 112, 112]         --\n",
       "│    │    └─Conv2d: 3-7                  [1, 256, 112, 112]        16,384\n",
       "│    │    └─BatchNorm2d: 3-8             [1, 256, 112, 112]        512\n",
       "│    │    └─Sequential: 3-9              [1, 256, 112, 112]        16,896\n",
       "│    │    └─ReLU: 3-10                   [1, 256, 112, 112]        --\n",
       "│    └─Bottleneck: 2-2                   [1, 256, 112, 112]        --\n",
       "│    │    └─Conv2d: 3-11                 [1, 64, 112, 112]         16,384\n",
       "│    │    └─BatchNorm2d: 3-12            [1, 64, 112, 112]         128\n",
       "│    │    └─ReLU: 3-13                   [1, 64, 112, 112]         --\n",
       "│    │    └─Conv2d: 3-14                 [1, 64, 112, 112]         36,864\n",
       "│    │    └─BatchNorm2d: 3-15            [1, 64, 112, 112]         128\n",
       "│    │    └─ReLU: 3-16                   [1, 64, 112, 112]         --\n",
       "│    │    └─Conv2d: 3-17                 [1, 256, 112, 112]        16,384\n",
       "│    │    └─BatchNorm2d: 3-18            [1, 256, 112, 112]        512\n",
       "│    │    └─ReLU: 3-19                   [1, 256, 112, 112]        --\n",
       "│    └─Bottleneck: 2-3                   [1, 256, 112, 112]        --\n",
       "│    │    └─Conv2d: 3-20                 [1, 64, 112, 112]         16,384\n",
       "│    │    └─BatchNorm2d: 3-21            [1, 64, 112, 112]         128\n",
       "│    │    └─ReLU: 3-22                   [1, 64, 112, 112]         --\n",
       "│    │    └─Conv2d: 3-23                 [1, 64, 112, 112]         36,864\n",
       "│    │    └─BatchNorm2d: 3-24            [1, 64, 112, 112]         128\n",
       "│    │    └─ReLU: 3-25                   [1, 64, 112, 112]         --\n",
       "│    │    └─Conv2d: 3-26                 [1, 256, 112, 112]        16,384\n",
       "│    │    └─BatchNorm2d: 3-27            [1, 256, 112, 112]        512\n",
       "│    │    └─ReLU: 3-28                   [1, 256, 112, 112]        --\n",
       "├─Sequential: 1-6                        [1, 512, 56, 56]          --\n",
       "│    └─Bottleneck: 2-4                   [1, 512, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-29                 [1, 128, 112, 112]        32,768\n",
       "│    │    └─BatchNorm2d: 3-30            [1, 128, 112, 112]        256\n",
       "│    │    └─ReLU: 3-31                   [1, 128, 112, 112]        --\n",
       "│    │    └─Conv2d: 3-32                 [1, 128, 56, 56]          147,456\n",
       "│    │    └─BatchNorm2d: 3-33            [1, 128, 56, 56]          256\n",
       "│    │    └─ReLU: 3-34                   [1, 128, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-35                 [1, 512, 56, 56]          65,536\n",
       "│    │    └─BatchNorm2d: 3-36            [1, 512, 56, 56]          1,024\n",
       "│    │    └─Sequential: 3-37             [1, 512, 56, 56]          132,096\n",
       "│    │    └─ReLU: 3-38                   [1, 512, 56, 56]          --\n",
       "│    └─Bottleneck: 2-5                   [1, 512, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-39                 [1, 128, 56, 56]          65,536\n",
       "│    │    └─BatchNorm2d: 3-40            [1, 128, 56, 56]          256\n",
       "│    │    └─ReLU: 3-41                   [1, 128, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-42                 [1, 128, 56, 56]          147,456\n",
       "│    │    └─BatchNorm2d: 3-43            [1, 128, 56, 56]          256\n",
       "│    │    └─ReLU: 3-44                   [1, 128, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-45                 [1, 512, 56, 56]          65,536\n",
       "│    │    └─BatchNorm2d: 3-46            [1, 512, 56, 56]          1,024\n",
       "│    │    └─ReLU: 3-47                   [1, 512, 56, 56]          --\n",
       "│    └─Bottleneck: 2-6                   [1, 512, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-48                 [1, 128, 56, 56]          65,536\n",
       "│    │    └─BatchNorm2d: 3-49            [1, 128, 56, 56]          256\n",
       "│    │    └─ReLU: 3-50                   [1, 128, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-51                 [1, 128, 56, 56]          147,456\n",
       "│    │    └─BatchNorm2d: 3-52            [1, 128, 56, 56]          256\n",
       "│    │    └─ReLU: 3-53                   [1, 128, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-54                 [1, 512, 56, 56]          65,536\n",
       "│    │    └─BatchNorm2d: 3-55            [1, 512, 56, 56]          1,024\n",
       "│    │    └─ReLU: 3-56                   [1, 512, 56, 56]          --\n",
       "│    └─Bottleneck: 2-7                   [1, 512, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-57                 [1, 128, 56, 56]          65,536\n",
       "│    │    └─BatchNorm2d: 3-58            [1, 128, 56, 56]          256\n",
       "│    │    └─ReLU: 3-59                   [1, 128, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-60                 [1, 128, 56, 56]          147,456\n",
       "│    │    └─BatchNorm2d: 3-61            [1, 128, 56, 56]          256\n",
       "│    │    └─ReLU: 3-62                   [1, 128, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-63                 [1, 512, 56, 56]          65,536\n",
       "│    │    └─BatchNorm2d: 3-64            [1, 512, 56, 56]          1,024\n",
       "│    │    └─ReLU: 3-65                   [1, 512, 56, 56]          --\n",
       "├─Sequential: 1-7                        [1, 1024, 28, 28]         --\n",
       "│    └─Bottleneck: 2-8                   [1, 1024, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-66                 [1, 256, 56, 56]          131,072\n",
       "│    │    └─BatchNorm2d: 3-67            [1, 256, 56, 56]          512\n",
       "│    │    └─ReLU: 3-68                   [1, 256, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-69                 [1, 256, 28, 28]          589,824\n",
       "│    │    └─BatchNorm2d: 3-70            [1, 256, 28, 28]          512\n",
       "│    │    └─ReLU: 3-71                   [1, 256, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-72                 [1, 1024, 28, 28]         262,144\n",
       "│    │    └─BatchNorm2d: 3-73            [1, 1024, 28, 28]         2,048\n",
       "│    │    └─Sequential: 3-74             [1, 1024, 28, 28]         526,336\n",
       "│    │    └─ReLU: 3-75                   [1, 1024, 28, 28]         --\n",
       "│    └─Bottleneck: 2-9                   [1, 1024, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-76                 [1, 256, 28, 28]          262,144\n",
       "│    │    └─BatchNorm2d: 3-77            [1, 256, 28, 28]          512\n",
       "│    │    └─ReLU: 3-78                   [1, 256, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-79                 [1, 256, 28, 28]          589,824\n",
       "│    │    └─BatchNorm2d: 3-80            [1, 256, 28, 28]          512\n",
       "│    │    └─ReLU: 3-81                   [1, 256, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-82                 [1, 1024, 28, 28]         262,144\n",
       "│    │    └─BatchNorm2d: 3-83            [1, 1024, 28, 28]         2,048\n",
       "│    │    └─ReLU: 3-84                   [1, 1024, 28, 28]         --\n",
       "│    └─Bottleneck: 2-10                  [1, 1024, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-85                 [1, 256, 28, 28]          262,144\n",
       "│    │    └─BatchNorm2d: 3-86            [1, 256, 28, 28]          512\n",
       "│    │    └─ReLU: 3-87                   [1, 256, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-88                 [1, 256, 28, 28]          589,824\n",
       "│    │    └─BatchNorm2d: 3-89            [1, 256, 28, 28]          512\n",
       "│    │    └─ReLU: 3-90                   [1, 256, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-91                 [1, 1024, 28, 28]         262,144\n",
       "│    │    └─BatchNorm2d: 3-92            [1, 1024, 28, 28]         2,048\n",
       "│    │    └─ReLU: 3-93                   [1, 1024, 28, 28]         --\n",
       "│    └─Bottleneck: 2-11                  [1, 1024, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-94                 [1, 256, 28, 28]          262,144\n",
       "│    │    └─BatchNorm2d: 3-95            [1, 256, 28, 28]          512\n",
       "│    │    └─ReLU: 3-96                   [1, 256, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-97                 [1, 256, 28, 28]          589,824\n",
       "│    │    └─BatchNorm2d: 3-98            [1, 256, 28, 28]          512\n",
       "│    │    └─ReLU: 3-99                   [1, 256, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-100                [1, 1024, 28, 28]         262,144\n",
       "│    │    └─BatchNorm2d: 3-101           [1, 1024, 28, 28]         2,048\n",
       "│    │    └─ReLU: 3-102                  [1, 1024, 28, 28]         --\n",
       "│    └─Bottleneck: 2-12                  [1, 1024, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-103                [1, 256, 28, 28]          262,144\n",
       "│    │    └─BatchNorm2d: 3-104           [1, 256, 28, 28]          512\n",
       "│    │    └─ReLU: 3-105                  [1, 256, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-106                [1, 256, 28, 28]          589,824\n",
       "│    │    └─BatchNorm2d: 3-107           [1, 256, 28, 28]          512\n",
       "│    │    └─ReLU: 3-108                  [1, 256, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-109                [1, 1024, 28, 28]         262,144\n",
       "│    │    └─BatchNorm2d: 3-110           [1, 1024, 28, 28]         2,048\n",
       "│    │    └─ReLU: 3-111                  [1, 1024, 28, 28]         --\n",
       "│    └─Bottleneck: 2-13                  [1, 1024, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-112                [1, 256, 28, 28]          262,144\n",
       "│    │    └─BatchNorm2d: 3-113           [1, 256, 28, 28]          512\n",
       "│    │    └─ReLU: 3-114                  [1, 256, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-115                [1, 256, 28, 28]          589,824\n",
       "│    │    └─BatchNorm2d: 3-116           [1, 256, 28, 28]          512\n",
       "│    │    └─ReLU: 3-117                  [1, 256, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-118                [1, 1024, 28, 28]         262,144\n",
       "│    │    └─BatchNorm2d: 3-119           [1, 1024, 28, 28]         2,048\n",
       "│    │    └─ReLU: 3-120                  [1, 1024, 28, 28]         --\n",
       "├─Sequential: 1-8                        [1, 2048, 14, 14]         --\n",
       "│    └─Bottleneck: 2-14                  [1, 2048, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-121                [1, 512, 28, 28]          524,288\n",
       "│    │    └─BatchNorm2d: 3-122           [1, 512, 28, 28]          1,024\n",
       "│    │    └─ReLU: 3-123                  [1, 512, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-124                [1, 512, 14, 14]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-125           [1, 512, 14, 14]          1,024\n",
       "│    │    └─ReLU: 3-126                  [1, 512, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-127                [1, 2048, 14, 14]         1,048,576\n",
       "│    │    └─BatchNorm2d: 3-128           [1, 2048, 14, 14]         4,096\n",
       "│    │    └─Sequential: 3-129            [1, 2048, 14, 14]         2,101,248\n",
       "│    │    └─ReLU: 3-130                  [1, 2048, 14, 14]         --\n",
       "│    └─Bottleneck: 2-15                  [1, 2048, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-131                [1, 512, 14, 14]          1,048,576\n",
       "│    │    └─BatchNorm2d: 3-132           [1, 512, 14, 14]          1,024\n",
       "│    │    └─ReLU: 3-133                  [1, 512, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-134                [1, 512, 14, 14]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-135           [1, 512, 14, 14]          1,024\n",
       "│    │    └─ReLU: 3-136                  [1, 512, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-137                [1, 2048, 14, 14]         1,048,576\n",
       "│    │    └─BatchNorm2d: 3-138           [1, 2048, 14, 14]         4,096\n",
       "│    │    └─ReLU: 3-139                  [1, 2048, 14, 14]         --\n",
       "│    └─Bottleneck: 2-16                  [1, 2048, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-140                [1, 512, 14, 14]          1,048,576\n",
       "│    │    └─BatchNorm2d: 3-141           [1, 512, 14, 14]          1,024\n",
       "│    │    └─ReLU: 3-142                  [1, 512, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-143                [1, 512, 14, 14]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-144           [1, 512, 14, 14]          1,024\n",
       "│    │    └─ReLU: 3-145                  [1, 512, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-146                [1, 2048, 14, 14]         1,048,576\n",
       "│    │    └─BatchNorm2d: 3-147           [1, 2048, 14, 14]         4,096\n",
       "│    │    └─ReLU: 3-148                  [1, 2048, 14, 14]         --\n",
       "├─Sequential: 1-9                        [1, 256, 14, 14]          --\n",
       "│    └─detnet_bottleneck: 2-17           [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-149                [1, 256, 14, 14]          524,288\n",
       "│    │    └─BatchNorm2d: 3-150           [1, 256, 14, 14]          512\n",
       "│    │    └─Conv2d: 3-151                [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-152           [1, 256, 14, 14]          512\n",
       "│    │    └─Conv2d: 3-153                [1, 256, 14, 14]          65,536\n",
       "│    │    └─BatchNorm2d: 3-154           [1, 256, 14, 14]          512\n",
       "│    │    └─Sequential: 3-155            [1, 256, 14, 14]          524,800\n",
       "│    └─detnet_bottleneck: 2-18           [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-156                [1, 256, 14, 14]          65,536\n",
       "│    │    └─BatchNorm2d: 3-157           [1, 256, 14, 14]          512\n",
       "│    │    └─Conv2d: 3-158                [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-159           [1, 256, 14, 14]          512\n",
       "│    │    └─Conv2d: 3-160                [1, 256, 14, 14]          65,536\n",
       "│    │    └─BatchNorm2d: 3-161           [1, 256, 14, 14]          512\n",
       "│    │    └─Sequential: 3-162            [1, 256, 14, 14]          --\n",
       "│    └─detnet_bottleneck: 2-19           [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-163                [1, 256, 14, 14]          65,536\n",
       "│    │    └─BatchNorm2d: 3-164           [1, 256, 14, 14]          512\n",
       "│    │    └─Conv2d: 3-165                [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-166           [1, 256, 14, 14]          512\n",
       "│    │    └─Conv2d: 3-167                [1, 256, 14, 14]          65,536\n",
       "│    │    └─BatchNorm2d: 3-168           [1, 256, 14, 14]          512\n",
       "│    │    └─Sequential: 3-169            [1, 256, 14, 14]          --\n",
       "├─AvgPool2d: 1-10                        [1, 256, 7, 7]            --\n",
       "├─Conv2d: 1-11                           [1, 30, 7, 7]             69,120\n",
       "├─BatchNorm2d: 1-12                      [1, 30, 7, 7]             60\n",
       "==========================================================================================\n",
       "Total params: 26,728,060\n",
       "Trainable params: 26,728,060\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 16.97\n",
       "==========================================================================================\n",
       "Input size (MB): 2.41\n",
       "Forward/backward pass size (MB): 719.35\n",
       "Params size (MB): 106.91\n",
       "Estimated Total Size (MB): 828.67\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchinfo\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "__all__ = ['ResNet', 'resnet50']\n",
    "\n",
    "\n",
    "model_urls = {'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth'}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class detnet_bottleneck(nn.Module):\n",
    "    # no expansion\n",
    "    # dilation = 2\n",
    "    # type B use 1x1 conv\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, block_type='A'):\n",
    "        super(detnet_bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            planes,\n",
    "            planes,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=2,\n",
    "            bias=False,\n",
    "            dilation=2)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            planes,\n",
    "            self.expansion *\n",
    "            planes,\n",
    "            kernel_size=1,\n",
    "            bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
    "\n",
    "        self.downsample = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes or block_type == 'B':\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_planes,\n",
    "                    self.expansion *\n",
    "                    planes,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False),\n",
    "                nn.BatchNorm2d(\n",
    "                    self.expansion *\n",
    "                    planes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.downsample(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1470):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        # self.layer5 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.layer5 = self._make_detnet_layer(in_channels=2048)\n",
    "        self.avgpool = nn.AvgPool2d(2)  # fit 448 input size\n",
    "        # self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.conv_end = nn.Conv2d(\n",
    "            256,\n",
    "            30,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            bias=False)\n",
    "        self.bn_end = nn.BatchNorm2d(30)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_detnet_layer(self, in_channels):\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            detnet_bottleneck(\n",
    "                in_planes=in_channels,\n",
    "                planes=256,\n",
    "                block_type='B'))\n",
    "        layers.append(\n",
    "            detnet_bottleneck(\n",
    "                in_planes=256,\n",
    "                planes=256,\n",
    "                block_type='A'))\n",
    "        layers.append(\n",
    "            detnet_bottleneck(\n",
    "                in_planes=256,\n",
    "                planes=256,\n",
    "                block_type='A'))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.avgpool(x)\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        # x = self.fc(x)\n",
    "        x = self.conv_end(x)\n",
    "        x = self.bn_end(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        # x = x.view(-1,7,7,30)\n",
    "        x = x.permute(0, 2, 3, 1)  # (-1,7,7,30)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "    if pretrained:\n",
    "        # model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "        model.load_state_dict(torch.load(\"/media/beyond/70f23ead-fa6d-4628-acf7-c82133c03245/home/beyond/Documents/ml/data/my/图像识别/yolo/checkpoints/model-20e.pth\",map_location=torch.device('cpu'))\n",
    "                          ,strict=False)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = resnet50(pretrained=True)\n",
    "model.to(config.device)\n",
    "torchinfo.summary(model, input_size=(1, 3, 448, 448))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model...\n",
      "predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1394747/530946860.py:301: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  img = Variable(img[None, :, :, :], volatile=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.1596, 0.4948, 0.2584,  ..., 0.4555, 0.4669, 0.5033],\n",
      "          [0.6655, 0.7219, 0.6589,  ..., 0.4572, 0.6218, 0.4867],\n",
      "          [0.3864, 0.7451, 0.6957,  ..., 0.3787, 0.4395, 0.4624],\n",
      "          ...,\n",
      "          [0.6735, 0.7859, 0.6114,  ..., 0.5226, 0.5779, 0.5514],\n",
      "          [0.4831, 0.7628, 0.5898,  ..., 0.5501, 0.5114, 0.3790],\n",
      "          [0.4542, 0.5874, 0.4995,  ..., 0.5352, 0.4172, 0.5330]],\n",
      "\n",
      "         [[0.6073, 0.7305, 0.3532,  ..., 0.6820, 0.7047, 0.6878],\n",
      "          [0.9307, 0.7722, 0.6431,  ..., 0.3262, 0.5214, 0.6216],\n",
      "          [0.8156, 0.6101, 0.5429,  ..., 0.5703, 0.4781, 0.3470],\n",
      "          ...,\n",
      "          [0.8126, 0.8261, 0.6679,  ..., 0.6111, 0.6956, 0.7345],\n",
      "          [0.7457, 0.7521, 0.6366,  ..., 0.7686, 0.5819, 0.6124],\n",
      "          [0.4782, 0.5324, 0.6625,  ..., 0.8393, 0.5972, 0.5915]],\n",
      "\n",
      "         [[0.7138, 0.7916, 0.4971,  ..., 0.6835, 0.5715, 0.5670],\n",
      "          [0.7936, 0.8616, 0.4400,  ..., 0.5473, 0.5030, 0.3847],\n",
      "          [0.4977, 0.6484, 0.4296,  ..., 0.9064, 0.5303, 0.3641],\n",
      "          ...,\n",
      "          [0.6596, 0.8266, 0.1927,  ..., 0.5838, 0.2424, 0.1393],\n",
      "          [0.2532, 0.7217, 0.3375,  ..., 0.4978, 0.5222, 0.3466],\n",
      "          [0.3365, 0.5479, 0.6471,  ..., 0.8364, 0.5933, 0.6345]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.6693, 0.4420, 0.5348,  ..., 0.7862, 0.5328, 0.7347],\n",
      "          [0.7720, 0.1287, 0.2912,  ..., 0.2504, 0.0796, 0.1019],\n",
      "          [0.4945, 0.1050, 0.3397,  ..., 0.2844, 0.0448, 0.2644],\n",
      "          ...,\n",
      "          [0.6657, 0.1329, 0.4976,  ..., 0.4352, 0.0901, 0.2128],\n",
      "          [0.1959, 0.0988, 0.6127,  ..., 0.5001, 0.2585, 0.5748],\n",
      "          [0.3975, 0.3740, 0.6769,  ..., 0.8772, 0.6302, 0.7406]],\n",
      "\n",
      "         [[0.3657, 0.2965, 0.6442,  ..., 0.7811, 0.6207, 0.5879],\n",
      "          [0.3854, 0.1421, 0.6662,  ..., 0.7251, 0.6747, 0.6390],\n",
      "          [0.1486, 0.1597, 0.7272,  ..., 0.7336, 0.7297, 0.5429],\n",
      "          ...,\n",
      "          [0.3907, 0.0948, 0.7814,  ..., 0.6573, 0.4592, 0.7005],\n",
      "          [0.2579, 0.1836, 0.8044,  ..., 0.7227, 0.5384, 0.6499],\n",
      "          [0.3092, 0.3363, 0.7224,  ..., 0.7350, 0.6100, 0.7596]],\n",
      "\n",
      "         [[0.3906, 0.5513, 0.5503,  ..., 0.5665, 0.6343, 0.5718],\n",
      "          [0.3204, 0.5802, 0.6762,  ..., 0.5510, 0.5645, 0.5903],\n",
      "          [0.2572, 0.4493, 0.7058,  ..., 0.3796, 0.6269, 0.5622],\n",
      "          ...,\n",
      "          [0.2530, 0.3748, 0.7218,  ..., 0.4094, 0.5633, 0.4597],\n",
      "          [0.3036, 0.3975, 0.7191,  ..., 0.5479, 0.5085, 0.3671],\n",
      "          [0.3655, 0.4390, 0.6176,  ..., 0.6538, 0.4633, 0.4586]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "a : tensor([[[[0.0228, 0.0707, 0.2584,  ..., 0.1350, 0.1384, 0.1492],\n",
      "          [0.2379, 0.1031, 0.6589,  ..., 0.1361, 0.1851, 0.1449],\n",
      "          [0.3409, 0.1064, 0.6957,  ..., 0.1109, 0.1287, 0.1354],\n",
      "          ...,\n",
      "          [0.6676, 0.1123, 0.6114,  ..., 0.1549, 0.1713, 0.1635],\n",
      "          [0.7833, 0.1090, 0.5898,  ..., 0.1659, 0.1542, 0.1143],\n",
      "          [0.9220, 0.0839, 0.4995,  ..., 0.1509, 0.1176, 0.1503]],\n",
      "\n",
      "         [[0.0868, 0.2472, 0.3532,  ..., 0.1970, 0.2035, 0.1986],\n",
      "          [0.2758, 0.2532, 0.6431,  ..., 0.0944, 0.1509, 0.1799],\n",
      "          [0.4022, 0.2300, 0.5429,  ..., 0.1494, 0.1253, 0.0909],\n",
      "          ...,\n",
      "          [0.6875, 0.2609, 0.6679,  ..., 0.1802, 0.2052, 0.2166],\n",
      "          [0.8208, 0.2503, 0.6366,  ..., 0.2199, 0.1665, 0.1752],\n",
      "          [0.9255, 0.2189, 0.6625,  ..., 0.2420, 0.1722, 0.1706]],\n",
      "\n",
      "         [[0.1020, 0.3988, 0.4971,  ..., 0.2127, 0.1778, 0.1764],\n",
      "          [0.2562, 0.4088, 0.4400,  ..., 0.1533, 0.1409, 0.1077],\n",
      "          [0.3568, 0.3783, 0.4296,  ..., 0.2779, 0.1625, 0.1116],\n",
      "          ...,\n",
      "          [0.6657, 0.4038, 0.1927,  ..., 0.1900, 0.0789, 0.0453],\n",
      "          [0.7505, 0.3888, 0.3375,  ..., 0.1539, 0.1615, 0.1072],\n",
      "          [0.9052, 0.3640, 0.6471,  ..., 0.2334, 0.1655, 0.1770]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0956, 0.6346, 0.5348,  ..., 0.2257, 0.1530, 0.2109],\n",
      "          [0.2531, 0.5898, 0.2912,  ..., 0.0666, 0.0212, 0.0271],\n",
      "          [0.3564, 0.5864, 0.3397,  ..., 0.0849, 0.0134, 0.0789],\n",
      "          ...,\n",
      "          [0.6665, 0.5904, 0.4976,  ..., 0.1256, 0.0260, 0.0614],\n",
      "          [0.7423, 0.5855, 0.6127,  ..., 0.1534, 0.0793, 0.1762],\n",
      "          [0.9139, 0.6249, 0.6769,  ..., 0.2500, 0.1796, 0.2111]],\n",
      "\n",
      "         [[0.0522, 0.7566, 0.6442,  ..., 0.2167, 0.1722, 0.1631],\n",
      "          [0.1979, 0.7346, 0.6662,  ..., 0.2109, 0.1963, 0.1859],\n",
      "          [0.3069, 0.7371, 0.7272,  ..., 0.1952, 0.1941, 0.1444],\n",
      "          ...,\n",
      "          [0.6272, 0.7278, 0.7814,  ..., 0.2146, 0.1499, 0.2287],\n",
      "          [0.7511, 0.7405, 0.8044,  ..., 0.2034, 0.1516, 0.1829],\n",
      "          [0.9013, 0.7623, 0.7224,  ..., 0.1999, 0.1659, 0.2066]],\n",
      "\n",
      "         [[0.0558, 0.9359, 0.5503,  ..., 0.1672, 0.1872, 0.1687],\n",
      "          [0.1886, 0.9400, 0.6762,  ..., 0.1676, 0.1717, 0.1796],\n",
      "          [0.3225, 0.9213, 0.7058,  ..., 0.1166, 0.1926, 0.1727],\n",
      "          ...,\n",
      "          [0.6076, 0.9107, 0.7218,  ..., 0.1149, 0.1581, 0.1290],\n",
      "          [0.7577, 0.9139, 0.7191,  ..., 0.1582, 0.1468, 0.1060],\n",
      "          [0.9094, 0.9199, 0.6176,  ..., 0.1837, 0.1302, 0.1289]]]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "1698418160.3525743\n",
      "1698418160.3526964\n",
      "1698418160.3527226\n",
      "1698418160.4131336\n",
      "1698418160.4389215\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6873,\n",
      "        0.0000, 0.0000, 0.6113, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "       grad_fn=<MaxBackward0>)\n",
      "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 11,\n",
      "         0,  0, 14,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0])\n",
      "1698418160.5013044\n",
      "d : tensor([[ 0.2588,  0.5344,  0.4635,  0.6496, 11.0000,  0.6873],\n",
      "        [ 0.6930,  0.4959,  0.4858,  0.7697, 14.0000,  0.6113]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "[[(12, 62), (220, 257), 'dog', '/media/beyond/70f23ead-fa6d-4628-acf7-c82133c03245/home/beyond/Documents/ml/data/my/图像识别/yolo/R-C.jpeg', 0.6873098611831665], [(202, 33), (421, 264), 'person', '/media/beyond/70f23ead-fa6d-4628-acf7-c82133c03245/home/beyond/Documents/ml/data/my/图像识别/yolo/R-C.jpeg', 0.6112982630729675]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "VOC_CLASSES = [   # always index 0\n",
    "    'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "    'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "    'cow', 'diningtable', 'dog', 'horse',\n",
    "    'motorbike', 'person', 'pottedplant',\n",
    "    'sheep', 'sofa', 'train', 'tvmonitor'] \n",
    "\n",
    "Color = [[0, 0, 0],\n",
    "         [128, 0, 0],\n",
    "         [0, 128, 0],\n",
    "         [128, 128, 0],\n",
    "         [0, 0, 128],\n",
    "         [128, 0, 128],\n",
    "         [0, 128, 128],\n",
    "         [128, 128, 128],\n",
    "         [64, 0, 0],\n",
    "         [192, 0, 0],\n",
    "         [64, 128, 0],\n",
    "         [192, 128, 0],\n",
    "         [64, 0, 128],\n",
    "         [192, 0, 128],\n",
    "         [64, 128, 128],\n",
    "         [192, 128, 128],\n",
    "         [0, 64, 0],\n",
    "         [128, 64, 0],\n",
    "         [0, 192, 0],\n",
    "         [128, 192, 0],\n",
    "         [0, 64, 128]]\n",
    "\n",
    "def compute_iou_matrix(a):\n",
    "    iou_m = torch.ones((a.size(0), a.size(0)))\n",
    "    for j in range(a.size(0)):\n",
    "        for k in range(j+1, a.size(0)):\n",
    "            xmin = torch.max(a[j,0] - a[j,2]/2, a[k,0]- a[j,2]/2) \n",
    "            xmax = torch.min(a[j,0] + a[j,2]/2, a[k,0]+ a[j,2]/2) \n",
    "            ymin = torch.max(a[j,1] - a[j,3]/2, a[k,1]- a[j,3]/2) \n",
    "            ymax = torch.min(a[j,1] + a[j,3]/2, a[k,1]+ a[j,3]/2) \n",
    "            interset = (xmax - xmin) * (ymax - ymin)\n",
    "            union = a[j,2] * a[j,3] + a[k,2] * a[k,3] - interset\n",
    "            iou = interset / union\n",
    "            iou_m[j,k] = iou\n",
    "            iou_m[k,j] = iou\n",
    "    return iou_m\n",
    "            \n",
    "import time\n",
    "def decode(outputs):\n",
    "    grid_num = 7\n",
    "    cell_size = 1. / grid_num\n",
    "\n",
    "    prob1 = outputs[:,:,:,4].unsqueeze(-1).expand_as(outputs[:,:,:,10:])  * outputs[:,:,:,10:] # softmax?\n",
    "    prob2 = outputs[:,:,:,9].unsqueeze(-1).expand_as(outputs[:,:,:,10:])  * outputs[:,:,:,10:]\n",
    "   \n",
    "    x = torch.arange(0,7).to(config.device).unsqueeze(0).unsqueeze(0).expand_as(outputs[:,:,:,0])* cell_size + outputs[:,:,:,0] * cell_size\n",
    "    y = torch.arange(0,7).to(config.device).unsqueeze(1).unsqueeze(0).expand_as(outputs[:,:,:,1])* cell_size + outputs[:,:,:,1] * cell_size\n",
    "    wh  = outputs[:,:,:,2:4]\n",
    "    real_coord = torch.concat([x.unsqueeze(-1),y.unsqueeze(-1), wh],dim=-1)\n",
    "    \n",
    "\n",
    "    x2 = torch.arange(0,7).to(config.device).unsqueeze(0).unsqueeze(0).expand_as(outputs[:,:,:,5])* cell_size + outputs[:,:,:,5] * cell_size\n",
    "    y2 = torch.arange(0,7).to(config.device).unsqueeze(1).unsqueeze(0).expand_as(outputs[:,:,:,6])* cell_size + outputs[:,:,:,6] * cell_size\n",
    "    wh2  = outputs[:,:,:,7:9]\n",
    "    real_coord2 = torch.concat([x2.unsqueeze(-1),y2.unsqueeze(-1), wh2],dim=-1)\n",
    "    \n",
    "    \n",
    "    a = torch.concat([real_coord[:,:,:,0:4], prob1], dim=-1)\n",
    "    b = torch.concat([real_coord2[:,:,:,0:4], prob2], dim=-1)\n",
    "\n",
    "    # a = torch.concat([outputs[:,:,:,0:4], prob1], dim=-1)\n",
    "    # b = torch.concat([outputs[:,:,:,5:9], prob2], dim=-1)\n",
    "    print(f\"a : {a}\")\n",
    "    print(f\"{time.time()}\")\n",
    "    a = a.view(-1,24)\n",
    "    b = b.view(-1,24)\n",
    "    a = torch.cat([a,b], dim=0)\n",
    "    print(f\"{time.time()}\")\n",
    "    # iou_m = compute_iou_matrix(a)\n",
    "    print(f\"{time.time()}\")\n",
    "    _,indices = torch.sort(a,dim=0, descending=True)\n",
    "    print(f\"{time.time()}\")\n",
    "    a[:,4:][a[:,4:] < config.min_confidence] = 0\n",
    "    for i in range(4, 24):\n",
    "        if a[:,i].sum() == 0:\n",
    "            continue\n",
    "        index = indices[:,i]\n",
    "        for m in range(index.size(0)-1):\n",
    "            j = index[m]\n",
    "            if a[j,i] == 0:\n",
    "                continue\n",
    "            for n in range(m+1, index.size(0)):\n",
    "                k = index[n]\n",
    "                if a[k,i] == 0:\n",
    "                    continue\n",
    "                xmin = torch.max(a[j,0] - a[j,2]/2, a[k,0]- a[j,2]/2) \n",
    "                xmax = torch.min(a[j,0] + a[j,2]/2, a[k,0]+ a[j,2]/2) \n",
    "                ymin = torch.max(a[j,1] - a[j,3]/2, a[k,1]- a[j,3]/2) \n",
    "                ymax = torch.min(a[j,1] + a[j,3]/2, a[k,1]+ a[j,3]/2) \n",
    "                interset = (xmax - xmin) * (ymax - ymin)\n",
    "                union = a[j,2] * a[j,3] + a[k,2] * a[k,3] - interset\n",
    "                iou = interset / union\n",
    "                # iou = iou_m[j,k]\n",
    "                if iou > config.max_interset_iou:\n",
    "                    a[k,i] = 0\n",
    "\n",
    "    print(f\"{time.time()}\")\n",
    "    maxprob, maxindex  = torch.max(a[:,4:],dim=1)\n",
    "    print(maxprob)\n",
    "    print(maxindex)\n",
    "    c = torch.concat([a[:,0:4], maxindex.unsqueeze(-1), maxprob.unsqueeze(-1)], dim=1)\n",
    "    # c[c[:,5] < config.min_confidence] = 0\n",
    "    d = c[c[:,5] != 0]\n",
    "    print(f\"{time.time()}\")\n",
    "    return d\n",
    "\n",
    "def predict(model, image_name):\n",
    "\n",
    "    result = []\n",
    "    image = cv2.imread(image_name)\n",
    "    h, w, _ = image.shape\n",
    "    img = cv2.resize(image, (448, 448))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    mean = (123, 117, 104)  # RGB\n",
    "    img = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])(img)\n",
    "    img = Variable(img[None, :, :, :], volatile=True)\n",
    "    img = img.to(config.device)\n",
    "    pred = model(img)  # 1x7x7x30\n",
    "    print(pred)\n",
    "    d = decode(pred)\n",
    "    print(f\"d : {d}\")\n",
    "    for i in range(d.size(0)):\n",
    "        box = d[i, :4]\n",
    "        x1 = int((box[0] - box[2]/2) * w)\n",
    "        x2 = int((box[0] + box[2]/2) * w)\n",
    "        y1 = int((box[1] - box[3]/2) * h)\n",
    "        y2 = int((box[1] + box[3]/2) * h)\n",
    "        cls_index = int(d[i,4].item())\n",
    "        prob = float(d[i,5].item())\n",
    "        result.append(\n",
    "            [(x1, y1), (x2, y2), VOC_CLASSES[cls_index], image_name, prob])\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # model = resnet50(pretrained=True)\n",
    "    print('load model...')\n",
    "    model.eval()\n",
    "    model.to(config.device)\n",
    "    # image_name = os.path.join(config.datasetdir, \"JPEGImages\", dataset.fnames[21])\n",
    "    # image_name = \"/media/beyond/70f23ead-fa6d-4628-acf7-c82133c03245/home/beyond/Documents/ml/data/my/图像识别/yolo/target.jpg\"\n",
    "    image_name =  \"/media/beyond/70f23ead-fa6d-4628-acf7-c82133c03245/home/beyond/Documents/ml/data/my/图像识别/yolo/R-C.jpeg\"\n",
    "    image = cv2.imread(image_name)\n",
    "    print('predicting...')\n",
    "    result = predict(model, image_name)\n",
    "    print(result)\n",
    "    for left_up, right_bottom, class_name, _, prob in result:\n",
    "        color = Color[VOC_CLASSES.index(class_name)]\n",
    "        cv2.rectangle(image, left_up, right_bottom, color, 2)\n",
    "        label = class_name + str(round(prob, 2))\n",
    "        text_size, baseline = cv2.getTextSize(\n",
    "            label, cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)\n",
    "        p1 = (left_up[0], left_up[1] - text_size[1])\n",
    "        cv2.rectangle(image, (p1[0] - 2, p1[1] - 2 - baseline), (p1[0] + text_size[0], p1[1] + text_size[1]), color, - 1)\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            label,\n",
    "            (p1[0],\n",
    "             p1[1] +\n",
    "                baseline),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.4,\n",
    "            (255,\n",
    "             255,\n",
    "             255),\n",
    "            1,\n",
    "            8)\n",
    "    # plt.imshow(image)\n",
    "    cv2.imwrite('result.jpg', image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
